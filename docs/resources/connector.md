---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "artie_connector Resource - terraform-provider-artie"
subcategory: ""
description: |-
  Artie Connector resource. This represents a database or data warehouse that you want to sync data from or to. Connectors are used by Pipelines and Source Readers.
---

# artie_connector (Resource)

Artie Connector resource. This represents a database or data warehouse that you want to sync data from or to. Connectors are used by Pipelines and Source Readers.

## Example Usage

```terraform
variable "postgres_password" {
  type      = string
  sensitive = true
}

resource "artie_connector" "postgres_dev" {
  name = "Postgres Dev"
  type = "postgresql"
  postgresql_config = {
    host     = "server.example.com"
    port     = 5432
    user     = "artie"
    password = var.postgres_password
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `type` (String) The type of connector. This must be one of the following: `bigquery`, `dynamodb`, `mongodb`, `mysql`, `mssql`, `oracle`, `postgresql`, `redshift`, `s3`, `snowflake`.

### Optional

- `bigquery_config` (Attributes) This should be filled out if the connector type is `bigquery`. (see [below for nested schema](#nestedatt--bigquery_config))
- `data_plane_name` (String) The name of the data plane this connector is in (if applicable; this does not apply to cloud-based connectors like BigQuery and Snowflake). If this is not set, we will use the default data plane for your account. To see the full list of supported data planes on your account, click on 'New pipeline' in our UI.
- `dynamodb_config` (Attributes) This should be filled out if the connector type is `dynamodb`. (see [below for nested schema](#nestedatt--dynamodb_config))
- `mongodb_config` (Attributes) This should be filled out if the connector type is `mongodb`. (see [below for nested schema](#nestedatt--mongodb_config))
- `mssql_config` (Attributes) This should be filled out if the connector type is `mssql`. (see [below for nested schema](#nestedatt--mssql_config))
- `mysql_config` (Attributes) This should be filled out if the connector type is `mysql`. (see [below for nested schema](#nestedatt--mysql_config))
- `name` (String) An optional human-readable label for this connector.
- `oracle_config` (Attributes) This should be filled out if the connector type is `oracle`. (see [below for nested schema](#nestedatt--oracle_config))
- `postgresql_config` (Attributes) This should be filled out if the connector type is `postgresql`. (see [below for nested schema](#nestedatt--postgresql_config))
- `redshift_config` (Attributes) This should be filled out if the connector type is `redshift`. (see [below for nested schema](#nestedatt--redshift_config))
- `s3_config` (Attributes) This should be filled out if the connector type is `s3`. (see [below for nested schema](#nestedatt--s3_config))
- `snowflake_config` (Attributes) This should be filled out if the connector type is `snowflake`. (see [below for nested schema](#nestedatt--snowflake_config))
- `ssh_tunnel_uuid` (String) This can point to an `artie_ssh_tunnel` resource if you need us to use an SSH tunnel to connect.

### Read-Only

- `uuid` (String)

<a id="nestedatt--bigquery_config"></a>
### Nested Schema for `bigquery_config`

Required:

- `credentials_data` (String, Sensitive) The credentials data for the Google Cloud service account that we should use to connect to BigQuery. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `location` (String) The location of the BigQuery dataset. This must be either `US` or `EU`.
- `project_id` (String) The ID of the Google Cloud project.


<a id="nestedatt--dynamodb_config"></a>
### Nested Schema for `dynamodb_config`

Required:

- `access_key_id` (String) The AWS Access Key ID for the service account we should use to connect to DynamoDB.
- `secret_access_key` (String, Sensitive) The AWS Secret Access Key for the service account we should use to connect to DynamoDB. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `stream_arn` (String) The ARN (Amazon Resource Name) of the DynamoDB Stream.


<a id="nestedatt--mongodb_config"></a>
### Nested Schema for `mongodb_config`

Required:

- `host` (String) The connection string for the MongoDB server. This can be either SRV or standard format.
- `password` (String, Sensitive) The password of the service account we will use to connect to the MongoDB database. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `username` (String) The username of the service account we will use to connect to the MongoDB database.


<a id="nestedatt--mssql_config"></a>
### Nested Schema for `mssql_config`

Required:

- `host` (String) The hostname of the Microsoft SQL Server. This must point to the primary host, not a read replica.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for Microsoft SQL Server is 1433.
- `username` (String) The username of the service account we will use to connect to the database.

Optional:

- `snapshot_host` (String) The hostname of the Microsoft SQL Server that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--mysql_config"></a>
### Nested Schema for `mysql_config`

Required:

- `host` (String) The hostname of the MySQL database. This must point to the primary host, not a read replica.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for MySQL is 3306.
- `username` (String) The username of the service account we will use to connect to the MySQL database. This service account needs enough permissions to read from the server binlogs.

Optional:

- `snapshot_host` (String) The hostname of the MySQL database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--oracle_config"></a>
### Nested Schema for `oracle_config`

Required:

- `host` (String) The hostname of the Oracle database. This must point to the primary host, not a read replica. This database must also have `ARCHIVELOG` mode and supplemental logging enabled.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for Oracle is 1521.
- `username` (String) The username of the service account we will use to connect to the Oracle database.

Optional:

- `snapshot_host` (String) The hostname of the Oracle database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--postgresql_config"></a>
### Nested Schema for `postgresql_config`

Required:

- `host` (String) The hostname of the PostgreSQL database. This can point to a read replica if you are using PostgreSQL 16 or higher, not on Amazon Aurora, and `hot_standby_feedback` is enabled; otherwise it must point to the primary host. This database must also have its `WAL_LEVEL` set to `logical`.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for PostgreSQL is 5432.
- `username` (String) The username of the service account we will use to connect to the PostgreSQL database. This service account needs enough permissions to create and read from the replication slot.

Optional:

- `snapshot_host` (String) The hostname of the PostgreSQL database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--redshift_config"></a>
### Nested Schema for `redshift_config`

Required:

- `endpoint` (String) The endpoint URL of your Redshift cluster. This should include both the host and port.
- `password` (String, Sensitive) The password for the service account we should use to connect to Redshift. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `username` (String) The username of the service account we should use to connect to Redshift.


<a id="nestedatt--s3_config"></a>
### Nested Schema for `s3_config`

Required:

- `access_key_id` (String) The AWS Access Key ID for the service account we should use to connect to S3.
- `region` (String) The AWS region where we should store your data in S3.
- `secret_access_key` (String, Sensitive) The AWS Secret Access Key for the service account we should use to connect to S3. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.


<a id="nestedatt--snowflake_config"></a>
### Nested Schema for `snowflake_config`

Required:

- `username` (String) The username of the service account we should use to connect to Snowflake.
- `virtual_dwh` (String) The name of your Snowflake virtual data warehouse.

Optional:

- `account_identifier` (String) The [account identifier](https://docs.snowflake.com/user-guide/admin-account-identifier) of your Snowflake account. We recommend using this instead of `account_url`.
- `account_url` (String) (Legacy) The [URL](https://docs.snowflake.com/user-guide/admin-account-identifier) of your Snowflake account. We recommend using `account_identifier` instead.
- `password` (String, Sensitive) (Legacy) The password for the service account we should use to connect to Snowflake. We recommend using `private_key` instead.
- `private_key` (String, Sensitive) The private key for the service account we should use to connect to Snowflake. We recommend using this instead of `password`.

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
# Import a connector by using its UUID, which you can find by:
# 1. Go to the pipeline overview page in the Artie UI (for a pipeline that uses this connector)
# 2. Open the dropdown in the top right corner
# 3. Select "View UUIDs" to see all related resource UUIDs
terraform import artie_connector.my_connector <connector_uuid>

# Then print the state and copy it into your terraform config file
# (be sure to remove all read-only fields, like `uuid`):
terraform state show artie_connector.my_connector
```

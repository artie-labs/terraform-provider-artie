---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "artie_connector Resource - terraform-provider-artie"
subcategory: ""
description: |-
  Artie Connector resource. This represents a database or data warehouse that you want to sync data from or to. Connectors are used by Pipelines and Source Readers.
---

# artie_connector (Resource)

Artie Connector resource. This represents a database or data warehouse that you want to sync data from or to. Connectors are used by Pipelines and Source Readers.

## Example Usage

```terraform
variable "postgres_password" {
  type      = string
  sensitive = true
}

resource "artie_connector" "postgres_dev" {
  name = "Postgres Dev"
  type = "postgresql"
  postgresql_config = {
    host     = "server.example.com"
    port     = 5432
    username = "artie"
    password = var.postgres_password
  }
}

variable "cockroach_password" {
  type      = string
  sensitive = true
}

resource "artie_connector" "cockroach_source" {
  name = "CockroachDB Source"
  type = "cockroach"
  cockroach_config = {
    host     = "my-cockroach-cluster.example.com"
    port     = 26257
    username = "artie"
    password = var.cockroach_password
  }
}

variable "gcp_credentials" {
  type      = string
  sensitive = true
}

resource "artie_connector" "gcs_destination" {
  name = "GCS Destination"
  type = "gcs"
  gcs_config = {
    project_id       = "my-gcp-project"
    credentials_data = var.gcp_credentials
  }
}

variable "aws_access_key_id" {
  type = string
}

variable "aws_secret_access_key" {
  type      = string
  sensitive = true
}

resource "artie_connector" "iceberg_s3tables" {
  name = "Iceberg S3 Tables"
  type = "iceberg"
  iceberg_config = {
    provider          = "s3tables"
    access_key_id     = var.aws_access_key_id
    secret_access_key = var.aws_secret_access_key
    bucket_arn        = "arn:aws:s3tables:us-east-1:123456789012:bucket/my-iceberg-bucket"
  }
}

variable "iceberg_rest_token" {
  type      = string
  sensitive = true
}

resource "artie_connector" "iceberg_rest_catalog" {
  name = "Iceberg REST Catalog"
  type = "iceberg"
  iceberg_config = {
    provider  = "rest"
    uri       = "https://workspace.cloud.databricks.com/api/2.1/unity-catalog/iceberg"
    token     = var.iceberg_rest_token
    warehouse = "my-warehouse"
  }
}

variable "iceberg_rest_client_id" {
  type = string
}

variable "iceberg_rest_client_secret" {
  type      = string
  sensitive = true
}

resource "artie_connector" "iceberg_rest_catalog_oauth2" {
  name = "Iceberg REST Catalog (OAuth2)"
  type = "iceberg"
  iceberg_config = {
    provider   = "rest"
    uri        = "https://workspace.cloud.databricks.com/api/2.1/unity-catalog/iceberg"
    credential = "${var.iceberg_rest_client_id}:${var.iceberg_rest_client_secret}"
    auth_uri   = "https://workspace.cloud.databricks.com/oidc/v1/token"
    warehouse  = "my-warehouse"
    scope      = "catalog"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `type` (String) The type of connector. This must be one of the following: `api`, `bigquery`, `cockroach`, `databricks`, `dynamodb`, `gcs`, `iceberg`, `mongodb`, `mssql`, `mysql`, `oracle`, `postgresql`, `redshift`, `s3`, `snowflake`.

### Optional

- `bigquery_config` (Attributes) This should be filled out if the connector type is `bigquery`. (see [below for nested schema](#nestedatt--bigquery_config))
- `cockroach_config` (Attributes) This should be filled out if the connector type is `cockroach`. (see [below for nested schema](#nestedatt--cockroach_config))
- `data_plane_name` (String) The name of the data plane this connector is in (if applicable; this does not apply to cloud-based connectors like BigQuery and Snowflake). If this is not set, we will use the default data plane for your account. To see the full list of supported data planes on your account, click on 'New pipeline' in our UI.
- `databricks_config` (Attributes) This should be filled out if the connector type is `databricks`. (see [below for nested schema](#nestedatt--databricks_config))
- `dynamodb_config` (Attributes) This should be filled out if the connector type is `dynamodb`. (see [below for nested schema](#nestedatt--dynamodb_config))
- `gcs_config` (Attributes) This should be filled out if the connector type is `gcs`. (see [below for nested schema](#nestedatt--gcs_config))
- `iceberg_config` (Attributes) This should be filled out if the connector type is `iceberg`. The `provider` field determines which additional fields are required: for `s3tables`, provide AWS credentials and bucket ARN; for `rest`, provide the catalog URI, warehouse, and authentication credentials. (see [below for nested schema](#nestedatt--iceberg_config))
- `mongodb_config` (Attributes) This should be filled out if the connector type is `mongodb`. (see [below for nested schema](#nestedatt--mongodb_config))
- `mssql_config` (Attributes) This should be filled out if the connector type is `mssql`. (see [below for nested schema](#nestedatt--mssql_config))
- `mysql_config` (Attributes) This should be filled out if the connector type is `mysql`. (see [below for nested schema](#nestedatt--mysql_config))
- `name` (String) An optional human-readable label for this connector.
- `oracle_config` (Attributes) This should be filled out if the connector type is `oracle`. (see [below for nested schema](#nestedatt--oracle_config))
- `postgresql_config` (Attributes) This should be filled out if the connector type is `postgresql`. (see [below for nested schema](#nestedatt--postgresql_config))
- `redshift_config` (Attributes) This should be filled out if the connector type is `redshift`. (see [below for nested schema](#nestedatt--redshift_config))
- `s3_config` (Attributes) This should be filled out if the connector type is `s3`. (see [below for nested schema](#nestedatt--s3_config))
- `snowflake_config` (Attributes) This should be filled out if the connector type is `snowflake`. (see [below for nested schema](#nestedatt--snowflake_config))
- `ssh_tunnel_uuid` (String) This can point to an `artie_ssh_tunnel` resource if you need us to use an SSH tunnel to connect.

### Read-Only

- `uuid` (String)

<a id="nestedatt--bigquery_config"></a>
### Nested Schema for `bigquery_config`

Required:

- `credentials_data` (String, Sensitive) The credentials data for the Google Cloud service account that we should use to connect to BigQuery. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `location` (String) The location of the BigQuery dataset. This must be either `US` or `EU`.
- `project_id` (String) The ID of the Google Cloud project.


<a id="nestedatt--cockroach_config"></a>
### Nested Schema for `cockroach_config`

Required:

- `host` (String) The hostname of the CockroachDB database.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for CockroachDB is 26257.
- `username` (String) The username of the service account we will use to connect to the CockroachDB database.

Optional:

- `snapshot_host` (String) The hostname of the CockroachDB database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.
- `snapshot_port` (Number) The port of the CockroachDB database that we should use to snapshot the database. If not provided, we will use the `port` value.


<a id="nestedatt--databricks_config"></a>
### Nested Schema for `databricks_config`

Required:

- `host` (String) The hostname of the Databricks cluster.
- `http_path` (String) The HTTP path of the Databricks cluster.
- `personal_access_token` (String, Sensitive) The personal access token for the service account we should use to connect to Databricks.
- `volume` (String) The volume of the Databricks cluster.


<a id="nestedatt--dynamodb_config"></a>
### Nested Schema for `dynamodb_config`

Required:

- `access_key_id` (String) The AWS Access Key ID for the service account we should use to connect to DynamoDB.
- `secret_access_key` (String, Sensitive) The AWS Secret Access Key for the service account we should use to connect to DynamoDB. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `stream_arn` (String) The ARN (Amazon Resource Name) of the DynamoDB Stream.


<a id="nestedatt--gcs_config"></a>
### Nested Schema for `gcs_config`

Required:

- `credentials_data` (String, Sensitive) The credentials data for the Google Cloud service account that we should use to connect to GCS. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `project_id` (String) The ID of the Google Cloud project.


<a id="nestedatt--iceberg_config"></a>
### Nested Schema for `iceberg_config`

Required:

- `provider` (String) The Iceberg provider type. Must be `s3tables` or `rest`.

Optional:

- `access_key_id` (String) The AWS Access Key ID for connecting to S3 Tables. Required if `provider` is `s3tables`.
- `auth_uri` (String) The OAuth2 token endpoint URL. Required when using `credential` authentication (without `token`).
- `bucket_arn` (String) The ARN of the S3 Tables table bucket (e.g. `arn:aws:s3tables:us-east-1:123456789012:bucket/my-bucket`). Required if `provider` is `s3tables`.
- `credential` (String, Sensitive) OAuth2 client credentials in the format `client_id:client_secret` for authenticating with the REST catalog. Either `token` or `credential` must be provided if `provider` is `rest`.
- `prefix` (String) An optional catalog prefix for namespacing in the REST catalog.
- `region` (String) The AWS region for S3 Tables. Optional; can be parsed from the `bucket_arn`.
- `scope` (String) The OAuth2 scope. Optional; defaults to `catalog` on the server side.
- `secret_access_key` (String, Sensitive) The AWS Secret Access Key for connecting to S3 Tables. Required if `provider` is `s3tables`. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable.
- `token` (String, Sensitive) A bearer token for authenticating with the REST catalog. Either `token` or `credential` must be provided if `provider` is `rest`.
- `uri` (String) The REST catalog endpoint URL. Required if `provider` is `rest`.
- `warehouse` (String) The warehouse identifier for the REST catalog. Required if `provider` is `rest`.


<a id="nestedatt--mongodb_config"></a>
### Nested Schema for `mongodb_config`

Required:

- `host` (String) The connection string for the MongoDB server. This can be either SRV or standard format.
- `password` (String, Sensitive) The password of the service account we will use to connect to the MongoDB database. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `username` (String) The username of the service account we will use to connect to the MongoDB database.


<a id="nestedatt--mssql_config"></a>
### Nested Schema for `mssql_config`

Required:

- `host` (String) The hostname of the Microsoft SQL Server. This must point to the primary host, not a read replica.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for Microsoft SQL Server is 1433.
- `username` (String) The username of the service account we will use to connect to the database.

Optional:

- `snapshot_host` (String) The hostname of the Microsoft SQL Server that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--mysql_config"></a>
### Nested Schema for `mysql_config`

Required:

- `host` (String) The hostname of the MySQL database. This must point to the primary host, not a read replica.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for MySQL is 3306.
- `username` (String) The username of the service account we will use to connect to the MySQL database. This service account needs enough permissions to read from the server binlogs.

Optional:

- `snapshot_host` (String) The hostname of the MySQL database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.
- `snapshot_port` (Number) The port of the MySQL database that we should use to snapshot the database. If not provided, we will use the `port` value.
- `tls_mode` (String) The TLS mode for the MySQL connection. Use `""` (empty string) to disable TLS, or `"preferred"` to enable TLS preferred mode.


<a id="nestedatt--oracle_config"></a>
### Nested Schema for `oracle_config`

Required:

- `host` (String) The hostname of the Oracle database. This must point to the primary host, not a read replica. This database must also have `ARCHIVELOG` mode and supplemental logging enabled.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for Oracle is 1521.
- `username` (String) The username of the service account we will use to connect to the Oracle database.

Optional:

- `snapshot_host` (String) The hostname of the Oracle database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--postgresql_config"></a>
### Nested Schema for `postgresql_config`

Required:

- `host` (String) The hostname of the PostgreSQL database. This can point to a read replica if you are using PostgreSQL 16 or higher, not on Amazon Aurora, and `hot_standby_feedback` is enabled; otherwise it must point to the primary host. This database must also have its `WAL_LEVEL` set to `logical`.
- `password` (String, Sensitive) The password of the service account. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `port` (Number) The default port for PostgreSQL is 5432.
- `username` (String) The username of the service account we will use to connect to the PostgreSQL database. This service account needs enough permissions to create and read from the replication slot.

Optional:

- `snapshot_host` (String) The hostname of the PostgreSQL database that we should use to snapshot the database. This can be a read replica and will only be used if this connector is being used as a source. If not provided, we will use the `host` value.


<a id="nestedatt--redshift_config"></a>
### Nested Schema for `redshift_config`

Required:

- `endpoint` (String) The endpoint URL of your Redshift cluster. This should include both the host and port.
- `password` (String, Sensitive) The password for the service account we should use to connect to Redshift. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.
- `username` (String) The username of the service account we should use to connect to Redshift.


<a id="nestedatt--s3_config"></a>
### Nested Schema for `s3_config`

Required:

- `access_key_id` (String) The AWS Access Key ID for the service account we should use to connect to S3.
- `region` (String) The AWS region where we should store your data in S3.
- `secret_access_key` (String, Sensitive) The AWS Secret Access Key for the service account we should use to connect to S3. We recommend storing this in a secret manager and referencing it via a *sensitive* Terraform variable, instead of putting it in plaintext in your Terraform config file.


<a id="nestedatt--snowflake_config"></a>
### Nested Schema for `snowflake_config`

Required:

- `username` (String) The username of the service account we should use to connect to Snowflake.
- `virtual_dwh` (String) The name of your Snowflake virtual data warehouse.

Optional:

- `account_identifier` (String) The [account identifier](https://docs.snowflake.com/user-guide/admin-account-identifier) of your Snowflake account. We recommend using this instead of `account_url`.
- `account_url` (String) (Legacy) The [URL](https://docs.snowflake.com/user-guide/admin-account-identifier) of your Snowflake account. We recommend using `account_identifier` instead.
- `password` (String, Sensitive) (Legacy) The password for the service account we should use to connect to Snowflake. We recommend using `private_key` instead.
- `private_key` (String, Sensitive) The private key for the service account we should use to connect to Snowflake. We recommend using this instead of `password`.

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
# Import a connector by using its UUID, which you can find by:
# 1. Go to the pipeline overview page in the Artie UI (for a pipeline that uses this connector)
# 2. Open the dropdown in the top right corner
# 3. Select "View UUIDs" to see all related resource UUIDs
terraform import artie_connector.my_connector <connector_uuid>

# Then print the state and copy it into your terraform config file
# (be sure to remove all read-only fields, like `uuid`):
terraform state show artie_connector.my_connector
```

---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "artie_source_reader Resource - terraform-provider-artie"
subcategory: ""
description: |-
  Artie Source Reader resource. This represents a process that reads data from a source connector and inserts it info Kafka. A Source Reader can be used by multiple Pipelines, e.g. to read from a single PostgreSQL replication slot and copy the data to multiple destinations.
---

# artie_source_reader (Resource)

Artie Source Reader resource. This represents a process that reads data from a source connector and inserts it info Kafka. A Source Reader can be used by multiple Pipelines, e.g. to read from a single PostgreSQL replication slot and copy the data to multiple destinations.

## Example Usage

```terraform
# A source reader that can only be used by one pipeline:
resource "artie_source_reader" "postgres_dev_reader" {
  name                               = "Postgres Dev Customers Reader"
  connector_uuid                     = artie_connector.postgres_dev.uuid
  database_name                      = "customers"
  postgres_replication_slot_override = "artie_reader"
  is_shared                          = false
}

# A source reader that can be used by multiple pipelines (must specify tables):
resource "artie_source_reader" "postgres_dev_reader" {
  name                               = "Postgres Dev Customers Reader"
  connector_uuid                     = artie_connector.postgres_dev.uuid
  database_name                      = "customers"
  postgres_replication_slot_override = "artie_reader"
  is_shared                          = true
  tables = {
    "public.account" = {
      name               = "account"
      schema             = "public"
      columns_to_exclude = ["email"]
    },
    "public.company" = {
      name   = "company"
      schema = "public"
    }
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `connector_uuid` (String) The source connector that we should read data from.

### Optional

- `backfill_batch_size` (Number) The number of rows to read from the source database in each batch while backfilling. Maximum allowed value is 50,000. Default is 5,000.
- `data_plane_name` (String) The name of the data plane to deploy this source reader in. If this is not set, we will use the default data plane for your account. To see the full list of supported data planes on your account, click on 'New deployment' in our UI.
- `database_name` (String) The name of the database we should read data from in the source connector. This should be specified if the source connector's type is DocumentDB, MongoDB, MySQL, MS SQL, Oracle (this maps to the service name), or PostgreSQL.
- `is_shared` (Boolean) If set to true, this source reader can be used by multiple pipelines.
- `name` (String) An optional human-readable label for this source reader.
- `one_topic_per_schema` (Boolean) If set to true, Artie will write all incoming CDC events into a single Kafka topic per schema. This is currently only supported if your source is Oracle and your account has this feature enabled.
- `oracle_container_name` (String) The name of the container (pluggable database) if the source type is Oracle and you are using a container database.
- `partition_suffix_regex_pattern` (String) If this source reader is reading any partitioned tables, this regex pattern should describe the expected suffix of each partition's name so that we can consume data from all partitions. If not set, this defaults to `_((default)|([0-9]{4})_(0[1-9]|1[012]))$` - meaning that for a table called `my_table` that's partitioned by month, we will detect partitions such as `my_table_default`, `my_table_2025_01`, `my_table_2025_02`, etc.
- `postgres_publication_name_override` (String) If set, this will override the name of the PostgreSQL publication. Otherwise, we will use our default value, `dbz_publication`. This is only applicable if the source type is PostgreSQL.
- `postgres_replication_slot_override` (String) If set, this will override the name of the PostgreSQL replication slot. Otherwise, we will use our default value, `artie`. This is only applicable if the source type is PostgreSQL.
- `tables` (Attributes Map) A map of tables from the source database that you want this source reader to include CDC events for. This should be specified if (and only if) the source reader has `is_shared` set to true, and it must include all tables that are specified in the `tables` attribute of any pipeline that uses this source reader. The key for each table should be formatted as `schema_name.table_name` if your source database uses schemas, otherwise just `table_name`. (see [below for nested schema](#nestedatt--tables))

### Read-Only

- `uuid` (String)

<a id="nestedatt--tables"></a>
### Nested Schema for `tables`

Required:

- `is_partitioned` (Boolean) Set this to true if the source table is partitioned.
- `name` (String) The name of the table in the source database.

Optional:

- `child_partition_schema_name` (String) If the source table is partitioned and its child partitions are in a different schema, this should specify the name of that schema.
- `columns_to_exclude` (List of String) An optional list of columns to exclude from CDC events. This cannot be used if `columns_to_include` is also specified.
- `columns_to_include` (List of String) An optional list of columns to include in CDC events. If not provided, all columns will be included. This cannot be used if `columns_to_exclude` is also specified.
- `schema` (String) The name of the schema the table belongs to in the source database. This must be specified if your source database uses schemas (such as PostgreSQL), e.g. `public`.
